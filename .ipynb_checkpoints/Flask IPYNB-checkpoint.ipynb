{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15cb7380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flask==2.1.2\n",
      "h5py==3.6.0\n",
      "tensorflow==2.8.0\n",
      "tensorflow_addons==0.16.1\n",
      "numpy==1.22.4\n",
      "pandas==1.3.4\n"
     ]
    }
   ],
   "source": [
    "import flask, os, io, h5py\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.restoration import (denoise_wavelet, estimate_sigma)\n",
    "from datetime import datetime\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdcd53fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DenoiseWavelet(data, type='BayesShrink'):\n",
    "    def BayesShrink():\n",
    "        im_bayes = denoise_wavelet(np.array(data), convert2ycbcr=True, multichannel=True,\n",
    "                                  method='BayesShrink', mode='soft', \n",
    "                                  rescale_sigma=True, wavelet_levels=4)\n",
    "        return im_bayes\n",
    "    \n",
    "    def VisuShrink():\n",
    "        sigma_est = estimate_sigma(np.array(data), multichannel=True, average_sigmas=True)\n",
    "        im_visu = denoise_wavelet(np.array(img), convert2ycbcr=True, multichannel=True,\n",
    "                                  method='VisuShrink', mode='soft', wavelet_levels=4,\n",
    "                                  sigma=sigma_est, rescale_sigma=True)\n",
    "        \n",
    "        return im_visu\n",
    "    \n",
    "    if type=='BayesShrink':\n",
    "        return BayesShrink()\n",
    "    elif type=='VisuShrink':\n",
    "        return VisuShrink()\n",
    "\n",
    "def create_feature(data_feature):\n",
    "    rs = []\n",
    "    data_denoise = DenoiseWavelet(data_feature, type='BayesShrink')\n",
    "    dt = tf.keras.utils.timeseries_dataset_from_array(data=data_denoise, targets=None,\n",
    "                                                          sequence_length=100, sequence_stride=20,\n",
    "                                                          shuffle=False)\n",
    "    for i in dt:\n",
    "        rs.append(i)\n",
    "        \n",
    "    rs = tf.stack(rs)\n",
    "    feature_rs = tf.data.Dataset.from_tensor_slices(rs)\n",
    "    feature_rs = feature_rs.cache().batch(56).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    return feature_rs\n",
    "\n",
    "def get_predict_p(arr, threshold=.5, types='Highest'):\n",
    "    arr = arr.reshape(-1)\n",
    "    \n",
    "    if types=='Highest':\n",
    "        if np.max(arr)>=threshold:\n",
    "            return np.argmax(arr)*20+275\n",
    "        else:\n",
    "            return -1\n",
    "    elif types=='Early':\n",
    "        for i, p_prob in enumerate(arr):\n",
    "            if p_prob>=threshold:\n",
    "                return i*20+275\n",
    "        else:\n",
    "            return -1\n",
    "    elif types=='Late':\n",
    "        i_thres = None\n",
    "        for i, p_prob in enumerate(arr):\n",
    "            if p_prob>=threshold:\n",
    "                i_thres = i\n",
    "        if i_thres!=None:\n",
    "            return i_thres*20+275\n",
    "        else:\n",
    "            return -1\n",
    "\n",
    "class DataGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, x_set, batch_size=196):\n",
    "        self.x = x_set\n",
    "        self.y = np.random.random(size=(x_set.shape))\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18d7d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD SAVEDMODEL ===\n",
    "\n",
    "class F1_Score(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='f1_score', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.f1 = self.add_weight(name='f1', initializer='zeros')\n",
    "        self.precision_fn = tf.keras.metrics.Precision(thresholds=0.5)\n",
    "        self.recall_fn = tf.keras.metrics.Recall(thresholds=0.5)\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        p = self.precision_fn(y_true, y_pred)\n",
    "        r = self.recall_fn(y_true, y_pred)\n",
    "        self.f1.assign(2 *((p*r)/(p + r + 1e-6)))\n",
    "        \n",
    "    def result(self):\n",
    "        return self.f1\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.precision_fn.reset_states()\n",
    "        self.recall_fn.reset_states()\n",
    "        self.f1.assign(0)\n",
    "\n",
    "PATH = 'C://Users/Zhafran/Documents/Data Science/BANGKIT - Capstone - Earthquake/Model Checkpoint/v1.1 (P-Wave Final)'\n",
    "p_model = tf.keras.models.load_model(PATH, custom_objects={'F1_Score':F1_Score,\n",
    "                                                              'loss':tfa.losses.SigmoidFocalCrossEntropy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b62387a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LOAD SAVEDMODEL ===\n",
    "\n",
    "PATH = 'C://Users/Zhafran/Documents/Data Science/BANGKIT - Capstone - Earthquake/Model Checkpoint/v5.1 (S-Wave 1 Final)/Best Model'\n",
    "s_model = tf.keras.models.load_model(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31eb7fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = 'C://Users/Zhafran/Documents/Data Science/BANGKIT - Capstone - TF Deployment'\n",
    "X = np.load(PATH+'/stead_indonesia_single_wavelength.npz')['arr_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4c3f27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhafran\\AppData\\Local\\Temp/ipykernel_2260/1392627789.py:3: FutureWarning: `multichannel` is a deprecated argument name for `denoise_wavelet`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  im_bayes = denoise_wavelet(np.array(data), convert2ycbcr=True, multichannel=True,\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\magics\\execution.py\", line 1324, in time\n",
      "    exec(code, glob, local_ns)\n",
      "  File \"<timed exec>\", line 21, in <module>\n",
      "  File \"C:\\Users\\Zhafran\\AppData\\Local\\Temp/ipykernel_2260/1392627789.py\", line 32, in create_feature\n",
      "    feature_rs = feature_rs.cache().batch(56).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
      "  File \"C:\\Users\\Zhafran\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1290, in prefetch\n",
      "    return PrefetchDataset(self, buffer_size, name=name)\n",
      "  File \"C:\\Users\\Zhafran\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 5480, in __init__\n",
      "    variant_tensor = gen_dataset_ops.prefetch_dataset(\n",
      "  File \"C:\\Users\\Zhafran\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\", line 5931, in prefetch_dataset\n",
      "    _result = pywrap_tfe.TFE_Py_FastPathExecute(\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2064, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\inspect.py\", line 1515, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\inspect.py\", line 1473, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\inspect.py\", line 751, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\inspect.py\", line 720, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\inspect.py\", line 705, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"C:\\Users\\Zhafran\\.conda\\envs\\ExVodka\\lib\\genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1323\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1324\u001b[1;33m                 \u001b[0mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1325\u001b[0m                 \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2260/1392627789.py\u001b[0m in \u001b[0;36mcreate_feature\u001b[1;34m(data_feature)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mfeature_rs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mfeature_rs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_rs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m56\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAUTOTUNE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mprefetch\u001b[1;34m(self, buffer_size, name)\u001b[0m\n\u001b[0;32m   1289\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1290\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mPrefetchDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1291\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, buffer_size, slack_period, name)\u001b[0m\n\u001b[0;32m   5479\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5480\u001b[1;33m       variant_tensor = gen_dataset_ops.prefetch_dataset(\n\u001b[0m\u001b[0;32m   5481\u001b[0m           \u001b[0minput_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mprefetch_dataset\u001b[1;34m(input_dataset, buffer_size, output_types, output_shapes, slack_period, legacy_autotune, buffer_size_min, metadata, name)\u001b[0m\n\u001b[0;32m   5930\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5931\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   5932\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"PrefetchDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2063\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2260/2329297523.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\nstart_ = 35075\\nend_ = start_+1200\\nepochs = 352\\nepochs_loop = 0\\n\\nis_p_detected = False\\nis_s_detected = False\\n\\nis_p_time_detected = False\\nis_s_time_detected = False\\n\\ntemp_s, temp_mag = 0, 0\\n\\np_s_mag_prediction = {}\\n\\nwhile True:\\n    try:\\n        sub_p_s_mag_prediction = {}\\n\\n        mult = 100\\n        data_pred = create_feature(X[start_:end_, :])\\n        y_pred = p_model.predict(data_pred)\\n\\n        high_ = get_predict_p(y_pred, types='Highest')\\n        early_ = get_predict_p(y_pred, types='Early')\\n        late_ = get_predict_p(y_pred, types='Late')\\n\\n        if (high_ and early_ and late_) != -1:\\n            if is_p_time_detected==False:\\n                p_time = datetime.now()\\n                p_year = p_time.year\\n                p_month = p_time.month\\n                p_day = p_time.day\\n                p_date = f'{p_day}/{p_month}/{p_year}'\\n\\n                p_hour = p_time.hour\\n                p_minute = p_time.minute\\n                p_second = p_time.second\\n                p_timestamp = p_hour*3600+p_minute*60+p_second\\n                is_p_time_detected = True\\n\\n            is_p_detected = True\\n\\n        if is_p_detected and ((high_ and early_ and late_) == -1):\\n            data_pred_np = DenoiseWavelet(X[start_-6000:start_, :], type='BayesShrink')\\n            data_pred_np = np.expand_dims(data_pred_np, axis=0)\\n                        \\n            data_pred = DataGenerator(data_pred_np, batch_size=196)\\n            y_pred = s_model.predict(data_pred.x).flatten()\\n\\n            pred_s, pred_mag = y_pred[0], y_pred[1]\\n            pred_s = np.exp(pred_s)\\n            pred_mag = np.exp(pred_mag)-1\\n                        \\n            is_s_detected = True\\n            \\n            s_time = datetime.now()\\n            s_year = s_time.year\\n            s_month = s_time.month\\n            s_day = s_time.day\\n            s_date = f'{s_day}/{s_month}/{s_year}'\\n\\n            s_hour = s_time.hour\\n            s_minute = s_time.minute\\n            s_second = s_time.second\\n            s_timestamp = s_hour*3600+s_minute*60+s_second\\n                                    \\n        if is_p_detected==False and is_s_detected==False:\\n            sub_p_s_mag_prediction.update({\\n                'P-Wave Date':-1,\\n                'P-Wave TimeStamp':-1,\\n                'S-Wave Time':-1,\\n                'S-Wave TimeStamp':-1,\\n                'Radius':-1,\\n                'Latitude':-8.4702,\\n                'Longitude':114.1521,\\n            })\\n            p_s_mag_prediction.update({epochs_loop+1:sub_p_s_mag_prediction})\\n\\n        elif is_p_detected==True and is_s_detected==False:\\n            sub_p_s_mag_prediction.update({\\n                'P-Wave Date':p_date,\\n                'P-Wave TimeStamp':p_timestamp,\\n                'S-Wave Date':-1,\\n                'S-Wave TimeStamp':-1,\\n                'Radius':-1,\\n                'Latitude':-8.4702,\\n                'Longitude':114.1521,\\n            })\\n            p_s_mag_prediction.update({epochs_loop+1:sub_p_s_mag_prediction})\\n\\n        elif is_p_detected==True and is_s_detected==True:\\n            sub_p_s_mag_prediction.update({\\n                'P-Wave Date':p_date,\\n                'P-Wave TimeStamp':p_timestamp,\\n                'S-Wave Date':s_date,\\n                'S-Wave TimeStamp':s_timestamp,\\n                'Radius':(s_timestamp-p_timestamp)*8.4,\\n                'Latitude':-8.4702,\\n                'Longitude':114.1521,\\n            })\\n            p_s_mag_prediction.update({epochs_loop+1:sub_p_s_mag_prediction})\\n            break\\n            \\n        epochs_loop+=1\\n        epochs+=1\\n        start_+=mult\\n        end_+=mult\\n        time.sleep(1.25)\\n\\n        \\n    except Exception as e:\\n        print(e)\\n        break\\n\\n#create an instance of Flask\\napp = flask.Flask('Earthquake Model Deployment')\\napp.config['JSONIFY_PRETTYPRINT_REGULAR'] = True\\n\\n@app.route('/')\\ndef home(): \\n    return flask.jsonify(p_s_mag_prediction)\\n\\napp.run(debug=False, port=8080)\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2404\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2406\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2407\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ExVodka\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1329\u001b[0m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m             \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1331\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1332\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2064\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2065\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2066\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2067\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1267\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m             )\n",
      "\u001b[1;32m~\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1122\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1124\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1126\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1082\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\ExVodka\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    380\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "start_ = 35075\n",
    "end_ = start_+1200\n",
    "epochs = 352\n",
    "epochs_loop = 0\n",
    "\n",
    "is_p_detected = False\n",
    "is_s_detected = False\n",
    "\n",
    "is_p_time_detected = False\n",
    "is_s_time_detected = False\n",
    "\n",
    "temp_s, temp_mag = 0, 0\n",
    "\n",
    "p_s_mag_prediction = {}\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        sub_p_s_mag_prediction = {}\n",
    "\n",
    "        mult = 100\n",
    "        data_pred = create_feature(X[start_:end_, :])\n",
    "        y_pred = p_model.predict(data_pred)\n",
    "\n",
    "        high_ = get_predict_p(y_pred, types='Highest')\n",
    "        early_ = get_predict_p(y_pred, types='Early')\n",
    "        late_ = get_predict_p(y_pred, types='Late')\n",
    "\n",
    "        if (high_ and early_ and late_) != -1:\n",
    "            if is_p_time_detected==False:\n",
    "                p_time = datetime.now()\n",
    "                p_year = p_time.year\n",
    "                p_month = p_time.month\n",
    "                p_day = p_time.day\n",
    "                p_date = f'{p_day}/{p_month}/{p_year}'\n",
    "\n",
    "                p_hour = p_time.hour\n",
    "                p_minute = p_time.minute\n",
    "                p_second = p_time.second\n",
    "                p_timestamp = p_hour*3600+p_minute*60+p_second\n",
    "                is_p_time_detected = True\n",
    "\n",
    "            is_p_detected = True\n",
    "\n",
    "        if is_p_detected and ((high_ and early_ and late_) == -1):\n",
    "            data_pred_np = DenoiseWavelet(X[start_-6000:start_, :], type='BayesShrink')\n",
    "            data_pred_np = np.expand_dims(data_pred_np, axis=0)\n",
    "                        \n",
    "            data_pred = DataGenerator(data_pred_np, batch_size=196)\n",
    "            y_pred = s_model.predict(data_pred.x).flatten()\n",
    "\n",
    "            pred_s, pred_mag = y_pred[0], y_pred[1]\n",
    "            pred_s = np.exp(pred_s)\n",
    "            pred_mag = np.exp(pred_mag)-1\n",
    "                        \n",
    "            is_s_detected = True\n",
    "            \n",
    "            s_time = datetime.now()\n",
    "            s_year = s_time.year\n",
    "            s_month = s_time.month\n",
    "            s_day = s_time.day\n",
    "            s_date = f'{s_day}/{s_month}/{s_year}'\n",
    "\n",
    "            s_hour = s_time.hour\n",
    "            s_minute = s_time.minute\n",
    "            s_second = s_time.second\n",
    "            s_timestamp = s_hour*3600+s_minute*60+s_second\n",
    "                                    \n",
    "        if is_p_detected==False and is_s_detected==False:\n",
    "            sub_p_s_mag_prediction.update({\n",
    "                'P-Wave Date':-1,\n",
    "                'P-Wave TimeStamp':-1,\n",
    "                'S-Wave Time':-1,\n",
    "                'S-Wave TimeStamp':-1,\n",
    "                'Radius':-1,\n",
    "                'Latitude':-8.4702,\n",
    "                'Longitude':114.1521,\n",
    "            })\n",
    "            p_s_mag_prediction.update({epochs_loop+1:sub_p_s_mag_prediction})\n",
    "\n",
    "        elif is_p_detected==True and is_s_detected==False:\n",
    "            sub_p_s_mag_prediction.update({\n",
    "                'P-Wave Date':p_date,\n",
    "                'P-Wave TimeStamp':p_timestamp,\n",
    "                'S-Wave Date':-1,\n",
    "                'S-Wave TimeStamp':-1,\n",
    "                'Radius':-1,\n",
    "                'Latitude':-8.4702,\n",
    "                'Longitude':114.1521,\n",
    "            })\n",
    "            p_s_mag_prediction.update({epochs_loop+1:sub_p_s_mag_prediction})\n",
    "\n",
    "        elif is_p_detected==True and is_s_detected==True:\n",
    "            sub_p_s_mag_prediction.update({\n",
    "                'P-Wave Date':p_date,\n",
    "                'P-Wave TimeStamp':p_timestamp,\n",
    "                'S-Wave Date':s_date,\n",
    "                'S-Wave TimeStamp':s_timestamp,\n",
    "                'Radius':(s_timestamp-p_timestamp)*8.4,\n",
    "                'Latitude':-8.4702,\n",
    "                'Longitude':114.1521,\n",
    "            })\n",
    "            p_s_mag_prediction.update({epochs_loop+1:sub_p_s_mag_prediction})\n",
    "            break\n",
    "            \n",
    "        epochs_loop+=1\n",
    "        epochs+=1\n",
    "        start_+=mult\n",
    "        end_+=mult\n",
    "        time.sleep(1.25)\n",
    "\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break\n",
    "\n",
    "#create an instance of Flask\n",
    "app = flask.Flask('Earthquake Model Deployment')\n",
    "app.config['JSONIFY_PRETTYPRINT_REGULAR'] = True\n",
    "\n",
    "@app.route('/')\n",
    "def home(): \n",
    "    return flask.jsonify(p_s_mag_prediction)\n",
    "\n",
    "app.run(debug=False, port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1012dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92146c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b66d11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8756fff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
